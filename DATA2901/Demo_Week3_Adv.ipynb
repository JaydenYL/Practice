{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Week 3 DATA2901 - Jupyter Notebooks and SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter notebooks can also directly include SQL commands - as long as the corresponding extensions are installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. IPython-SQL Extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iPhython kernel supports third-party extensions which can provide additional functionality via so-called **magics**. There **ipython-sql** extension is one extension which extends Jupyter notebooks with SQL.\n",
    "\n",
    "It first needs to be installed though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you are on you own machine, install ipython-sql directly there\n",
    "#\n",
    "# If you use one of the Jupyter servers of the School of Computer Science, open a Jupyter terminal and type\n",
    "\n",
    "pip install -U --user ipython-sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the on-off installation of the extension on your computer, we next need to load this extension at the start of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, we have **SQL** **inline magics**, invoked with an <font color=\"purple\">**%sql**</font> at the start of the line, as well as **SQL cell magics** which are invoked with a double <font color=\"purple\">**%%sql**</font> at the start of the cell, available in this notebook.\n",
    "\n",
    "### 1.1 Connect to a new database:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some connection string patterns for various databases:\n",
    "\n",
    "| DBMS          | Connection String |\n",
    "| ------------- |:-------------|\n",
    "|**PostgreSQL:**| postgresql://scott:tiger@localhost/mydatabase|\n",
    "|**MySQL:**     | mysql://scott:tiger@localhost/foo|\n",
    "|**Oracle:**    | oracle://scott:tiger@127.0.0.1:1521/sidname|\n",
    "|**SQL Server:**| mssql+pyodbc://scott:tiger@mydsn|\n",
    "|**SQLite:**    | sqlite:///foo.db|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to connect to out postgresql server\n",
    "#%sql postgresql://USER:PASSWORD@soitpw11d59.shared.sydney.edu.au/USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to connect or create a SQLite database\n",
    "%sql sqlite:///test.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Execute SQL\n",
    "Let's save some dummy data and query it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE TABLE testtab (x int, y char);\n",
    "INSERT INTO testtab VALUES (1, 'a');\n",
    "INSERT INTO testtab VALUES (2, 'b');\n",
    "SELECT * FROM testtab;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Bind Variable to SQL query\n",
    "You can input data from a local Python variable into the SQL statements;\n",
    "The python variable must be in the local scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textvar = 'Hello World'\n",
    "%sql SELECT :textvar AS \"bind variable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# how to use an SQL SELECT statement as a simple calculator ;)\n",
    "%sql SELECT 7*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the value from a Python variable as argument for a parameterised SQL query:\n",
    "search = \"b\"\n",
    "%sql SELECT * FROM testtab WHERE y = :search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Variable Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = %sql SELECT x FROM testtab WHERE y = 'a'\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multi-line query, you need to use a **<<** syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql result_set <<\n",
    "SELECT *\n",
    "  FROM testtab;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking te type of the result_set, we see that it is a special resultset type provided by this SQL extension\n",
    "type(result_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a SQL magic resultset knows the names of its columns\n",
    "result_set.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can access individual values by row number and attribute name\n",
    "result_set[0].x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Pandas and SQL\n",
    "SQL magic has also a very nice integration with the pandas library.\n",
    "SQL query results can be converted to regular pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = result_set.DataFrame()\n",
    "print(type(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on the result as dataframe the normal pandas commands can be used\n",
    "result_set.DataFrame().head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing CSV into SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start by loading the CSV file into a Pandas data frame - which allows to configure quite a bit the import\n",
    "import pandas as pd\n",
    "stations = pd.read_csv('MajorPowerStations_v2.csv')\n",
    "stations.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sqlite databsae\n",
    "%sql sqlite:///powerstationsNew.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist the dataframe in the new sqlite databse\n",
    "%sql PERSIST stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether we were successful\n",
    "%sql SELECT * FROM stations LIMIT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's also have a look at the metadata in SQLite \n",
    "# the following PRAGMA command is sqlite specific - it retrieves the schema of table stations\n",
    "%sql PRAGMA table_info(stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another look into SQLite's metadata:\n",
    "# Which database objects do we have in the current database?\n",
    "%sql SELECT name, type FROM sqlite_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Performance Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do another performance comparison of SQLite and Pandas and Python.\n",
    "\n",
    "**Important:** Note that the runtime results completely depend on the computer hardware where the Jupyter notebook is executed.\n",
    "\n",
    "We are again using a slightly larger dataset here from the US Bureau of Transport Statistics about the on-time performance of major US airlines. The dataset of the flight performance for January 2019 is a CSV file of about 54 MB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's check the format of this file by looking at the header line and the first data row\n",
    "! head -n 2 ontime_performance_2019-01.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: Determine average departure delay of United Airlines\n",
    "The next experiment is an analysis without grouping or sorting. It requires to scan the full dataset and determine the average DEP_DELAY valuy for those entries of the 'UA' carrier (that means filtering by United Airlines flights).\n",
    "\n",
    "#### Measurement 1.1: Determine average departure delay of United Airlines using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# load OnTime Performance dataset for 2019-01 into Pandas DataFrame\n",
    "import pandas as pd\n",
    "data = pd.read_csv('ontime_performance_2019-01.csv')\n",
    "\n",
    "# What is the average delay of United Airlines flights?\n",
    "uadelays  = data.loc[data['OP_UNIQUE_CARRIER']=='UA']\n",
    "print(\"Average delay:\",uadelays['DEP_DELAY'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measurement 1.2: Determine average departure delay of United Airlines using Unix and awk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%%bash\n",
    "awk 'BEGIN  { FS=\",\" }\n",
    "     /\"UA\"/ { if ($8!=\"\") { delay_sum+=$8; delay_count++} } \n",
    "     END    { print \"Average delay:\",delay_sum/delay_count }' \"ontime_performance_2019-01.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measurement 1.3: Determine average departure delay of United Airlines using sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql sqlite:///ontime_performance_2019-01.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%sql SELECT * FROM sqlite_master;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%%sql\n",
    "SELECT AVG(dep_delay) AS \"Average Delay\"\n",
    "  FROM OnTime\n",
    " WHERE op_unique_carrier='UA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when comparing those execution times, we did not include in the last measurement the time to load the data into the sqlite database in the first place. However, this needs to be done only once, afterwards you cna query it as often as you like, while in the Pandas approach, you have to load the data from CSV into a pandas DataFrame very time you run the notebook... (but granted, also only once per notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL Magic also supports direct plotting of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make sure we are on the right database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql @ontime_performance_2019-01.db\n",
    "SELECT COUNT(*) FROM OnTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = %sql SELECT origin, COUNT(fl_date) FROM OnTime GROUP BY origin ORDER BY COUNT(fl_date) DESC LIMIT 5\n",
    "\n",
    "%matplotlib inline\n",
    "result.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it.\n",
    "\n",
    "# The End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
