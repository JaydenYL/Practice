{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA2001 - Week 2\n",
    "## Data Exploration with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing all required Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Reading data from a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demo, we are working with an example dataset about the major Australian power stations as published on data.gov.au:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import CSV data into a Pandas DataFrame - and let's have a first look at its shape and content\n",
    "rawData = pd.read_csv('MajorPowerStations_v2.csv')\n",
    "\n",
    "print(rawData.shape)\n",
    "rawData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Inconsistent Data Examples - Inspect the 9th, 23rd, 31st, and 4th last records (using iloc[])\n",
    "We often find some inconsistent data entries in a dataset. The following code demonstrates hot to inspects some specific data records within a DataFrame using the **iloc[]** function to go by row index. Note that row index start at 0. As we can see, there are NaN and \"< Null >\" values which we will need to address when preparing this data for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxLs = np.append(np.array([9,23,31])-1, -4)\n",
    "rawData.iloc[idxLs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Rename DataFrame Columns\n",
    "The DataFrame columns are automatically named after the header row of the CSV file. You can change those names, e.g. to have it consistent with other dataset or simply to have it shorter, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see the current axis titles\n",
    "rawData.axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to check the current names of the columns as read from the CSV's header line:\n",
    "rawData.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a working copy of the raw data\n",
    "wrkData = rawData.copy()\n",
    "\n",
    "# Rename columns\n",
    "wrkData.rename(columns={\n",
    "    'OBJECTID': 'oid',\n",
    "    'CLASS': 'class',\n",
    "    'FID': 'fid',\n",
    "    'NAME': 'name',\n",
    "    'OPERATIONALSTATUS': 'status',\n",
    "    'OWNER': 'owner',\n",
    "    'GENERATIONTYPE': 'type',\n",
    "    'PRIMARYFUELTYPE': 'fueltype',\n",
    "    'PRIMARYSUBFUELTYPE': 'fuelsubtype',\n",
    "    'GENERATIONMW': 'power',\n",
    "    'GENERATORNUMBER': 'numGen',\n",
    "    'SUBURB': 'suburb',\n",
    "    'STATE': 'state',\n",
    "    'SPATIALCONFIDENCE': 'spConf',\n",
    "    'REVISED': 'revised',\n",
    "    'COMMENT': 'comment',\n",
    "    'LATITUDE': 'lat',\n",
    "    'LONGITUDE': 'long'\n",
    "}, inplace=True)\n",
    "\n",
    "# Check df column data types\n",
    "print(wrkData.dtypes)\n",
    "\n",
    "# View\n",
    "wrkData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also drop some columns which we do not need\n",
    "wrkData.drop(['fid'], axis=1, inplace=True)\n",
    "wrkData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrkData['name'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Data Cleaning and Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check what we have read in so far\n",
    "# wrkData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Cleaning nominal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the names of owners again as done before in the lecture using  Refine\n",
    "wrkData['owner'].unique()\n",
    "\n",
    "# the same, but alphabetically sorted\n",
    "#wrkData.sort_values(by=['owner'])['owner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# potential fix\n",
    "wrkData['owner'].replace(to_replace=\"AGL\", value=\"AGL Energy Pty Ltd\", inplace=True)\n",
    "wrkData['owner'].replace(to_replace=\"AGL Energy\", value=\"AGL Energy Pty Ltd\", inplace=True)\n",
    "wrkData.sort_values(by=['owner'])['owner'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Date and Timestamps\n",
    "Date values should be converted to datetime types to enable corresponding date functions and comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 'revised' column was initially read by Panadas as an int values\n",
    "print(\"before conversion:\",wrkData['revised'].dtypes)\n",
    "print(\"  date of 1st row:\",wrkData.iloc[1]['revised'],\"\\n\")\n",
    "\n",
    "# 'revised' is actually a date\n",
    "# Convert 'revised' column to datetime\n",
    "wrkData['revised'] = pd.to_datetime(wrkData['revised'],format=\"%Y%m%d\")\n",
    "\n",
    "#\n",
    "print(\"after conversion:\",wrkData['revised'].dtypes)\n",
    "print(\" datetime of 1st row:\",wrkData.iloc[1]['revised'])\n",
    "print(\" date of 1st row:\",wrkData.iloc[1]['revised'].date())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Cleaning numerical data (ordinal, interval, ratio) \n",
    "For aggregation and plotting, we need numerical variables to be free of placehodler strings. Depending on which function you want to use, removing NaN might also be needed (e.g. not possible for int columns). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN values which we generated by read_csv()\n",
    "wrkData['numGen'].fillna(0, inplace=True)\n",
    "wrkData['fuelsubtype'].fillna('', inplace=True)\n",
    "wrkData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# try to convert numGen and power to integer values  (note: will fail)\n",
    "print(\"before conversion:\",wrkData['numGen'].dtypes)\n",
    "print(\"before conversion:\",wrkData['power'].dtypes)\n",
    "\n",
    "wrkData['numGen'] = wrkData['numGen'].astype(int)\n",
    "wrkData['power']  = wrkData['power'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above's code failed because there is an unparsable string in the 'numGen' column which we need to fix first before we can proceed with the type conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Fix the read_csv() call and pass missing values list including \"<Null>\"\n",
    "# missing_values = [\"<Null>\"]\n",
    "# rawData = pd.read_csv('...', na_values = missing_values)\n",
    "\n",
    "# Option 2: replace <Null> value in current numGen column\n",
    "wrkData['numGen'].replace(to_replace=\"<Null>\", value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"before conversion:\",wrkData['numGen'].dtypes)\n",
    "\n",
    "# try converting to numeric data types again\n",
    "wrkData['numGen'] = wrkData['numGen'].astype(int)\n",
    "\n",
    "print(\"after conversion:\",wrkData['numGen'].dtypes)\n",
    "print(\"after conversion:\",wrkData['power'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check df column data types\n",
    "print(wrkData.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Data Exploration and Descriptive Statistics\n",
    "The next step is to explore the data with following Python / Pandas statements.\n",
    "\n",
    "### Descriptive Statistics over all data entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which status values are used for the major Power Stations?\n",
    "wrkData['status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which type of power stations are listed in the dataset?\n",
    "# notice that there is again a \"< Null >\" and \"nan\" values used somewhere which we also would need to fix...\n",
    "wrkData['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what kind of fule is used by major power stations to produce energy?\n",
    "wrkData['fueltype'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the value range of the power generation capacity across all stations?\n",
    "print(\"Minimum power generation capacity:\", wrkData['power'].min(), \"MW\")\n",
    "print(\"Maximum power generation capacity:\", wrkData['power'].max(), \"MW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the average and mean of the power generation capacity across all stations?\n",
    "print(\"Average power generation capacity:\", wrkData['power'].mean(), \"MW\")\n",
    "print(\"Median  power generation capacity:\", wrkData['power'].median(), \"MW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "We can also compute those descriptive statistics for just a selected sub-set of the dataset using the **.loc[]** function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which thermal solar power stations are in the dataset?\n",
    "wrkData.loc[wrkData['type']=='Solar Thermal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many wind parks are listed in the dataset?\n",
    "wrkData.loc[wrkData['type']=='Wind Turbine', 'name'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also can specify complex filter conditions, e.g. connected with a logical and (**&**), and show only selected columns in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are large wind parks with more than 100MW power capacity? \n",
    "# just showing name, type, pwoer, numGen and state attributes\n",
    "wrkData.loc[ (wrkData['type']=='Wind Turbine') & (wrkData['power']>100),  ['name', 'type', 'power', 'numGen', 'state'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What do you think: Do we generate in Australia more power via wind or via solar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total installed wind power:  \",wrkData.loc[wrkData['fueltype']=='Wind', 'power'].sum(), \"MW\")\n",
    "print(\"Total installed solar power: \",wrkData.loc[wrkData['fueltype']=='Solar','power'].sum(), \"MW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping\n",
    "Sometimes, it is useful to **group** data by a certain attribute and then to summarise all entries of the same group, so that we can compare different groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which is the most frequent class of power station?\n",
    "wrkData['class'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the frequency distribution of the power station class?\n",
    "# this can be done with the groupby() function, followed by a size() for each group\n",
    "classDistr = wrkData.groupby('class').size()\n",
    "print(classDistr)\n",
    "print(classDistr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the total power output capacity per class of power stations?\n",
    "wrkData.groupby('class')['power'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Visualisations\n",
    "### (a) Frequency Plot / Histogram\n",
    "Produce a bar chart of Which primary fuel types are used. Bar chart plotting reference: https://pythonspot.com/matplotlib-bar-chart/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fuelTypeDistr = wrkData.groupby('fueltype').size().reset_index(name='numStations')\n",
    "\n",
    "# Plot\n",
    "plt.bar(fuelTypeDistr['fueltype'], fuelTypeDistr['numStations'], alpha=0.5, align='center')\n",
    "plt.xticks(rotation=40)\n",
    "plt.title('Major Australian Power Stations')\n",
    "plt.xlabel('Primary Fuel Type')\n",
    "plt.ylabel('Count')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Histogram with Binning\n",
    "Plot the number of generators per power station in bins of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pyExpFreq = wrkData['power'].hist(bins=10, rwidth=0.9, color='#607c8e')\n",
    "plt.title('Histogram of Power Output')\n",
    "plt.xlabel('Power Output [MW]')\n",
    "plt.ylabel('Number of Power Stations')\n",
    "plt.grid(axis='y', alpha=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Scatter Plot for comparing power and size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()\n",
    "sub = plt.subplot()\n",
    "wrkData.plot.scatter(x='numGen', y='power', c='DarkBlue', ax=sub)\n",
    "sub.set_xlim(0,50)\n",
    "plt.title('Power Output vs Num Generators')\n",
    "plt.xlabel('Num Generators')\n",
    "plt.ylabel('Output [MW]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to color code the data points in the scatter plot by station type. To be able to give colors per point, we need to create a numeric encoding of the fuel type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which fule types exist again?\n",
    "wrkData['fueltype'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the frequency distribution of the fuel types?\n",
    "fuelTypeDistr = wrkData.groupby('fueltype').size()\n",
    "print(fuelTypeDistr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign colors to some selected fuel types\n",
    "# the numbers and the order chosen are up-to you.\n",
    "# we have chosen an order that works well with the color schemes used in the subsequent plots\n",
    "wrkData['fuelEncoding'] = wrkData['fueltype'].map({\n",
    "    'Biogas': 1,\n",
    "    'Wind': 2,\n",
    "    'Solar': 3,\n",
    "    'Water': 4,\n",
    "    'Natural Gas': 5,\n",
    "    'Coal Seam Methane': 6,\n",
    "    'Coal': 7\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use this encoding column to color our plot\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()\n",
    "sub = plt.subplot()\n",
    "wrkData.plot.scatter(x='numGen', y='power', c='fuelEncoding', ax=sub)\n",
    "sub.set_xlim(0,50)\n",
    "plt.title('Power Output vs Num Generators')\n",
    "plt.xlabel('Num Generators')\n",
    "plt.ylabel('Output [MW]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot of the fuel types is more easier to interpret when we use colour. We can either define dedicated colour values, or use one of the pre-defined colour maps from Matplotlib. Choosing an appropriate colouring scheme helps quite a bit to see that coal or natural gas power stations have fewer generators, but a large output, vs. e.g. wind farms with a high number of generators, but lower overall output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the same plot as before, but using a more vivid color scheme (colormap='Accent')\n",
    "# (for available colormaps from matplotlib, see https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html)\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()\n",
    "sub = plt.subplot()\n",
    "wrkData.plot.scatter(x='numGen',y='power',c='fuelEncoding',colormap='Accent',ax=sub)\n",
    "sub.set_xlim(0,50)\n",
    "plt.title('Power Output vs Num Generators')\n",
    "plt.xlabel('Num Generators')\n",
    "plt.ylabel('Output [MW]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Boxplots for Likert-Scale\n",
    "Visualise boxplots for {spConf}, the spatial confidence value on the GPS location of the stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.yticks(np.arange(1, 5, 1.0))\n",
    "fig = wrkData.boxplot(['spConf']).set_title('Spatial Confidence')\n",
    "plt.grid(axis='y', alpha=0) # disable grid lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The boxplot shows that most entries have a high to very-high location confidence (4 or 5), but there are two outliers with very low confidence in thgeir location values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's it for today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
