{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Week 2 DATA2901 - Jupyter Notebooks and Unix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter notebooks can include Unix commands - as long as the server is running under Unix itself.\n",
    "\n",
    "These commands have access to the same file system than the notebook itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Executing Unix commands in iPython Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can execute Unix commands in a Jupyter Python notebook after a <font color='purple'>**!**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list the content of the current directory\n",
    "! ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pwd prints the name of the current work directory\n",
    "! pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unix commands can refer to environment variables (using the usual _$var_ notation) that can be set with <font color='purple'>**%env**</font> in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%env filename = MajorPowerStations_v2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show the first two lines of the file referred to via the variable $filename\n",
    "! head -n 2 $filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also execute pipelines of Unix commands this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list all unique OPERATIONALSTATUS values\n",
    "! cut -f 5 -d , $filename | sort | uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list all unique OPERATIONALSTATUS values - ignoring the CSV file's header line (starting from line 2)\n",
    "! tail -n +2 $filename | cut -f 5 -d , | sort | uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# which classes of power stations do we have - and how many of each?\n",
    "! tail -n +2 $filename | cut -f 2 -d , | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also access the help pages for the Unix commands using the **man** command; just be careful with long help texts..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if you want to check the user manual of a Unix command, use 'man' (careful with long help texts)\n",
    "! man uniq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sed** is the Unix stream editor which is handy for doing some basic string repalcements for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sed example (cf. adv lecture slides and man page for more information about sed)\n",
    "! echo \"hello world\"\n",
    "! echo \"hello world\" | sed -e 's/hello/bonjours/g'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connecting Python with Unix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, the examples were just invoking Unix commands and including then in the notebook their result as output text. But we can also cvonnect Python and Unix more directly:\n",
    " - Use <font color=\"red\">__{var}__</font> to receive data ferom a Python variable into a Unix command as input.\n",
    " - Use <font color=\"purple\"> = ! </font> as part of a variable assignment to receive results from Unix into a Python variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's prepare a Python variable\n",
    "text = \"\"\"Standing at the limit of an endless ocean\n",
    "Stranded like a runaway, lost at sea\n",
    "City on a rainy day down in the harbour\n",
    "Watching as the grey clouds shadow the bay\n",
    "Looking everywhere 'cause I had to find you\n",
    "This is not the way that I remember it here\n",
    "Anyone will tell you its a prisoner island\n",
    "Hidden in the summer for a million years\n",
    "\"\"\"\n",
    "print(text)\n",
    "\n",
    "# send the Python 'text' to Unix and modify it with sed; result is assigned to 'modified_text'\n",
    "modified_text = ! echo \"{text}\" | sed -e 's/ocean/beach/g'\n",
    "print(modified_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the text is actually processed line-by-line by the Unix commands, and returned as a string list (<tt>IPython.utils.text.SList</tt>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(modified_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A <tt>text.SList</tt> type supports several special fields which help working with these lists of texts.\n",
    "\n",
    "Fro example, to see it in its original multi-line text format, we need to join the different lines with a newline in between. This is done by the **.n** special field of the <tt>SList</tt> type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print result as one concatenated string with newlines in-between\n",
    "print( modified_text.n )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several other very useful functions defined on these <tt>SList</tt>s, such as a **grep()** or a **sort()** function too. For more information about the <tt>IPython.utils.text.SList</tt> type, see the iPython online documentation at: https://ipython.readthedocs.io/en/stable/api/generated/IPython.utils.text.html#IPython.utils.text.SList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** What would happen if you would use the patter 's/way/PATH/g' with sed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. IPython Magics Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the advanced lecture slides, we explained that Jupyter is quite an extensible eccosystem with multiple options to add new functionality. Python notebooks are actually executed by an **iPython kernel** and this iPhython kernel in turn supports own extensions, called **magics**. There are quite a few of those magics already built-in.\n",
    "\n",
    "An **inline magic** is invoked with an <font color=\"purple\">**%**</font> at the start of the line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%lsmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **cell magic** is invoked with a double <font color=\"purple\">**%%**</font> at the start of the cell and then affects everything following it in the same notebook cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# measure the execution time needed for a cell\n",
    "! tail -n +2 $filename | cut -f 2 -d , | sort | uniq -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# the %%bash cell magic allows to run multi-line Unix shell scripts.\n",
    " \n",
    " tail -n +2 $filename \\\n",
    "| cut -f 2 -d ,       \\\n",
    "| sort                \\\n",
    "| uniq -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<h3>Heading Level 3</h3>\n",
    "<p>The quick brown fox <b>jumps</b> over the lazy dog.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%latex\n",
    "$$ E = m c^2$$\n",
    "$$f(\\omega) = \\int_{0}^{\\infty} \\! f(x) \\mathrm{e}^{-2\\pi{}i\\omega x}\\, \\mathrm{d}x $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Performance Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's do a simple performance comparison between Python+Pandas and Unix shell commands for some simple data analysis.\n",
    "\n",
    "**Important:** Note that the runtime results completely depend on the computer hardware where the Jupyter notebook is executed.\n",
    "\n",
    "We are using a slightly larger dataset here from the US Bureau of Transport Statistics about the on-time performance of major US airlines. The dataset of the flight performance for January 2019 is a CSV file of about 54 MB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 52992\r\n",
      "drwxr-sr-x 3 uroehm linuxusers     4096 Mar  7 21:50 .\r\n",
      "drwxr-sr-x 9 uroehm linuxusers     4096 Mar  4 13:39 ..\r\n",
      "-rw-r--r-- 1 uroehm linuxusers    21862 Mar  7 21:50 Demo_Week2_Adv.ipynb\r\n",
      "drwxr-sr-x 2 uroehm linuxusers     4096 Mar  4 13:40 .ipynb_checkpoints\r\n",
      "-rw-r--r-- 1 uroehm linuxusers    91310 Mar  4 14:07 MajorPowerStations_v2.csv\r\n",
      "-rw-r--r-- 1 uroehm linuxusers 54125805 Mar  5 10:57 ontime_performance_2019-01.csv\r\n",
      "-rw-r--r-- 1 uroehm linuxusers       12 Mar  5 11:13 test.txt\r\n"
     ]
    }
   ],
   "source": [
    "! ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FL_DATE,OP_UNIQUE_CARRIER,ORIGIN,ORIGIN_STATE_NM,DEST,DEST_STATE_NM,DEP_TIME,DEP_DELAY,ARR_TIME,ARR_DELAY,CANCELLATION_CODE,AIR_TIME,DISTANCE\r\n",
      "2019-01-28,\"DL\",\"DFW\",\"Texas\",\"SLC\",\"Utah\",\"1233\",-8.00,\"1437\",0.00,\"\",158.00,989.00\r\n"
     ]
    }
   ],
   "source": [
    "# let's check the format of this file by looking at the header line and the first data row\n",
    "! head -n 2 ontime_performance_2019-01.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: List Top-3 Airports by Flight Departures \n",
    "\n",
    "The first experiment requires to read the full 54MB dataset, group (and sort) by 'ORIGIN', count the flights per origin, and then print the top-3 values.\n",
    "\n",
    "#### Measurement 1.1 List Top-3 Airports by Flight Departures using Pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGIN\n",
      "ATL    31155\n",
      "ORD    26216\n",
      "DFW    23063\n",
      "dtype: int64\n",
      "CPU times: user 1.03 s, sys: 1.12 s, total: 2.15 s\n",
      "Wall time: 1.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# load OnTime Performance dataset for 2019-01 into Pandas DataFrame\n",
    "import pandas as pd\n",
    "data = pd.read_csv('ontime_performance_2019-01.csv')\n",
    "\n",
    "# What is the frequency distribution of the origin airports?\n",
    "originDistr = data.groupby('ORIGIN').size()\n",
    "print(originDistr.nlargest(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measurement 1.2: List Top-3 Airports by Flight Departures using Unix commands\n",
    "_(careful - CPU times only measured for Jupyter process, does not include CPU time of Unix sub-commands; you need to compare Wall times.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  31155 \"ATL\"\n",
      "  26216 \"ORD\"\n",
      "  23063 \"DFW\"\n",
      "CPU times: user 50 ms, sys: 23 ms, total: 73 ms\n",
      "Wall time: 2.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# find the top 3 origin airports by number of flights\n",
    "! cut -f 3 -d , 'ontime_performance_2019-01.csv' | sort | uniq -c |  sort --sort=numeric -r |  head -n 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measurement 1.3: List Top-3 Airports by Flight Departures using Unix' awk command\n",
    "\n",
    "The 'awk' command is a very powerful and flexible data processing command in Unix, which allows to pattern match certain lines of the input, and the execute a small code funtion (including local variables, condition statements and loops) on ythe matching lines. BEGIN is for program initialization; the code block after END is executed at the end of processing the file with awk. Again, when comparing times, concentrate on _wall time_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"ATL\" 31155\n",
      "\"ORD\" 26216\n",
      "\"DFW\" 23063\n",
      "CPU times: user 4 ms, sys: 2 ms, total: 6 ms\n",
      "Wall time: 435 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "awk 'BEGIN {FS=\",\"} \n",
    "           {origin[$3]++}\n",
    "     END {for(i in origin) print i,origin[i]}'  \"ontime_performance_2019-01.csv\" \\\n",
    "| sort -nr -k2 \\\n",
    "| head -n 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measurement 1.4: List Top-3 Airports by Flight Departures using Perl\n",
    "\n",
    "Perl is another popular test and pattern processing language; we are not covering Perl in more depth in this unit, but just for fun let's see how fast or slow it is on this task compared to the previous alternatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31155\t\"ATL\"\n",
      "26216\t\"ORD\"\n",
      "23063\t\"DFW\"\n",
      "CPU times: user 42 ms, sys: 20 ms, total: 62 ms\n",
      "Wall time: 2.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "! perl -F, -l -an -e '$h{$F[2]}++; END{for $w (sort {$h{$b}<=>$h{$a}} keys %h) {print \"$h{$w}\\t$w\"}}' 'ontime_performance_2019-01.csv' | head -n 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Determine average departure delay of United Airlines\n",
    "The next experiment is an analysis without grouping or sorting. It requires to scan the full dataset and determine the average DEP_DELAY valuy for those entries of the 'UA' carrier (that means filtering by United Airlines flights).\n",
    "\n",
    "#### Measurement 2.1: Determine average departure delay of United Airlines using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46915 560776.0 12.1293448403\n",
      "CPU times: user 824 ms, sys: 144 ms, total: 968 ms\n",
      "Wall time: 971 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# load OnTime Performance dataset for 2019-01 into Pandas DataFrame\n",
    "import pandas as pd\n",
    "data = pd.read_csv('ontime_performance_2019-01.csv')\n",
    "\n",
    "# What is the average delay of United Airlines flights?\n",
    "uadelays  = data.loc[data['OP_UNIQUE_CARRIER']=='UA']\n",
    "print(uadelays['OP_UNIQUE_CARRIER'].count(),uadelays['DEP_DELAY'].sum(),uadelays['DEP_DELAY'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measurement 2.2: Determine average departure delay of United Airlines using Unix and awk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46915 560776 11.953\n",
      "CPU times: user 1e+03 µs, sys: 8 ms, total: 9 ms\n",
      "Wall time: 381 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "awk 'BEGIN  {FS=\",\"}\n",
    "     /\"UA\"/ {delay_sum+=$8; delay_count++} \n",
    "     END    {print delay_count, delay_sum, delay_sum/delay_count}' \"ontime_performance_2019-01.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the results of the two queries above differ: While pandas computed a mean departure dealy of 12.1 min, awk found it to be a mean of 11.9min. \n",
    "\n",
    "Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason is that Pandas by default ignores any NaN entries in the DataDrame, i.e. flights with unknown delay.\n",
    "If we re-code the awk program to also ignore those lines, we get the same average value of 12.1 min:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46233 560776 12.1293\n",
      "CPU times: user 5 ms, sys: 4 ms, total: 9 ms\n",
      "Wall time: 383 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "awk 'BEGIN  { FS=\",\" }\n",
    "     /\"UA\"/ { if ($8!=\"\") { delay_sum+=$8; delay_count++} } \n",
    "     END    { print delay_count, delay_sum, delay_sum/delay_count }' \"ontime_performance_2019-01.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it.\n",
    "\n",
    "Please keep in mind that the performance values shown above are the ones for the current Jupyter server at USyd. They will differ on your own machine, and Python+Pandas can on a more modern machine with enough memory be faster than Unix...\n",
    "\n",
    "# The End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
